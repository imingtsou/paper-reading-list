\begin{abstract}
The study and adoption of deep learning methods has led to significant progress in different application domains. As deep learning continues to show promise and its utilization matures, so does the infrastructure and software needed to support it. Various frameworks have been developed in recent years to facilitate both implementation and training of deep learning networks. As deep learning has also evolved to becoming distributed, there's a growing need for frameworks that can support execution across many machine. While deep learning frameworks restricted to running on a single machine have been studied and compared, frameworks which support deep learning distributed across multiple machines are relatively less known and well-studied. This paper seeks to bridge that gap by surveying, summarizing, and comparing frameworks which currently support distributed execution, including Tensorflow, Deeplearning4j, MXNet, H2O, and CaffeOnSpark. 

%This paper provides a sample of a LaTeX document for final submission
%to Sigkdd Explorations, the official newsletter of ACM Sigkdd. This is
%a modified version of the ACM Proceedings sample file.
%
%The developers have tried to include every imaginable sort
%of ``bells and whistles", such as a subtitle, footnotes on
%title, subtitle and authors, as well as in the text, and
%every optional component (e.g. Acknowledgements, Additional
%Authors, Appendices), not to mention examples of
%equations, theorems, tables and figures.
%
%To make best use of this sample document, run it through \LaTeX\
%and BibTeX, and compare this source code with the printed
%output produced by the dvi file.
\end{abstract}
